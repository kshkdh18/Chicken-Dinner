# MIRROR Repository Overview

The **MIRROR** repository develops a next-generation multi-agent-based security and verification system for large language models (LLMs). With the rapid integration of LLMs in enterprises, identifying and addressing their security vulnerabilities has become a survival imperative.

This system evolves security verification into a continuous and proactive interaction process involving 'attacks' (Red Teaming) and 'defenses' (Blue Teaming).

## Key Features:
- **Multi-Agent Ecosystem**: Consists of four core personas: Attack, Defense, Judge, Report agents, interacting organically.
- **Garak**: A tool for detecting vulnerabilities in LLMs with a comprehensive attack probe library.
- **LiteLLM**: A lightweight LLM proxy and guardrail management tool.

### Goals:
- Establish an interactive ecosystem that leverages the strengths of both Garak and LiteLLM to transition from simple tool combinations to an intelligent security framework.

Integrating current orchestration technologies such as OpenAI's Agents SDK is expected to enhance the system's capabilities significantly.

---

For more detailed plans, refer to the original documentation.